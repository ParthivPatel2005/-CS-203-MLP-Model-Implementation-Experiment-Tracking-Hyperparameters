{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)  # Reshape for one-hot encoding\n",
    "\n",
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = ohe.fit_transform(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP model class\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, output_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_units)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_units, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Training function with hyperparameter tuning\n",
    "def train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, torch.max(y_batch, 1)[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            y_pred.extend(torch.argmax(outputs, axis=1).numpy())\n",
    "            y_true.extend(torch.argmax(y_batch, axis=1).numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, f1, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search\n",
    "batch_sizes = [2, 4]\n",
    "learning_rates = [1e-3, 1e-5]\n",
    "epochs_list = [1, 3, 5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epochs_list:\n",
    "            # Prepare DataLoader\n",
    "            train_dataset = TensorDataset(X_train, y_train)\n",
    "            test_dataset = TensorDataset(X_test, y_test)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Initialize model, loss, optimizer\n",
    "            model = MLPModel(input_size=4, hidden_units=16, output_size=3)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            accuracy, f1, y_true, y_pred = train_and_evaluate(model, train_loader, test_loader, criterion, optimizer, epochs)\n",
    "            \n",
    "            # Store results\n",
    "            results.append((batch_size, lr, epochs, accuracy, f1))\n",
    "            print(f'Batch Size: {batch_size}, LR: {lr}, Epochs: {epochs} -> Accuracy: {accuracy:.4f}, F1: {f1:.4f}')\n",
    "            \n",
    "            # Confusion matrix\n",
    "            cm = confusion_matrix(y_true, y_pred)\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'], yticklabels=['Class 0', 'Class 1', 'Class 2'])\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.title(f\"Confusion Matrix (BS={batch_size}, LR={lr}, Epochs={epochs})\")\n",
    "            plt.show()\n",
    "            \n",
    "            # Show 5 test samples\n",
    "            print(\"Sample Predictions:\")\n",
    "            for i in range(5):\n",
    "                print(f\"Input: {X_test[i].numpy()}, Prediction: {y_pred[i]}, Truth: {y_true[i]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all results\n",
    "print(\"\\nHyperparameter Search Results:\")\n",
    "for res in results:\n",
    "    print(f\"Batch Size: {res[0]}, LR: {res[1]}, Epochs: {res[2]} -> Accuracy: {res[3]:.4f}, F1: {res[4]:.4f}\")\n",
    "\n",
    "# Identify the best hyperparameters\n",
    "best_params = max(results, key=lambda x: x[3])  # Sorting by accuracy\n",
    "print(f\"\\nBest Hyperparameters: Batch Size={best_params[0]}, Learning Rate={best_params[1]}, Epochs={best_params[2]} -> Accuracy={best_params[3]:.4f}, F1={best_params[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install autogluon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/LR_grid\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       7.67 GB / 31.65 GB (24.2%)\n",
      "Disk Space Avail:   50.03 GB / 430.79 GB (11.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\LR_grid\"\n",
      "Train Data Rows:    800\n",
      "Train Data Columns: 10\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7852.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 640, Val Rows: 160\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'LR': [{'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LinearModel ...\n",
      "\tWarning: Exception caused LinearModel to fail during training... Skipping this model.\n",
      "\t\tThe 'C' parameter of LogisticRegression must be a float in the range (0.0, inf]. Got [0.01, 0.1, 1, 10] instead.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\models\\lr\\lr_model.py\", line 233, in _fit\n",
      "    model = model.fit(**fit_args)\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0.0, inf]. Got [0.01, 0.1, 1, 10] instead.\n",
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "Warning: AutoGluon did not successfully train any models\n",
      "AutoGluon training complete, total runtime = 0.27s ... Best model: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, params \u001b[38;5;129;01min\u001b[39;00m param_grid\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 21\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_grid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ Corrected this line\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     perf \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n\u001b[0;32m     25\u001b[0m     grid_results[model] \u001b[38;5;241m=\u001b[39m perf\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39mgargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1299\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_strategy \u001b[38;5;241m=\u001b[39m fit_strategy\n\u001b[1;32m-> 1299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1307\u001b[0m, in \u001b[0;36mTabularPredictor._fit\u001b[1;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_fit_kwargs)\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_post_fit_vars()\n\u001b[1;32m-> 1307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_post_fit_kwargs)\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1630\u001b[0m, in \u001b[0;36mTabularPredictor._post_fit\u001b[1;34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit, num_cpus, num_gpus, refit_full_kwargs, fit_strategy, raise_on_no_models_fitted)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_names():\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_no_models_fitted:\n\u001b[1;32m-> 1630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo models were trained successfully during fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1632\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Inspect the log output or increase verbosity to determine why no models were fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1633\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1634\u001b[0m         )\n\u001b[0;32m   1636\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: No models found, skipping post_fit logic...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call."
     ]
    }
   ],
   "source": [
    "# Load or generate data\n",
    "def get_data():\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "    return pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)]), pd.Series(y, name='target')\n",
    "\n",
    "X, y = get_data()\n",
    "df = X.copy()\n",
    "df['target'] = y\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameter grids\n",
    "param_grid = {\n",
    "    'LR': {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']},  # Logistic Regression\n",
    "    'RF': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]},  # Random Forest\n",
    "    'XGB': {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [50, 100]}  # XGBoost\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_results = {}\n",
    "for model, params in param_grid.items():\n",
    "    predictor = TabularPredictor(label='target', path=f'models/{model}_grid').fit(\n",
    "        train_data, hyperparameters={model: params}  # ✅ Corrected this line\n",
    "    )\n",
    "    perf = predictor.evaluate(test_data)\n",
    "    grid_results[model] = perf\n",
    "\n",
    "# Random Search\n",
    "random_results = {}\n",
    "for model, params in param_grid.items():\n",
    "    predictor = TabularPredictor(label='target', path=f'models/{model}_random').fit(\n",
    "        train_data, hyperparameters={model: params},  # ✅ Corrected this line\n",
    "        hyperparameter_tune_kwargs={'searcher': 'random'}\n",
    "    )\n",
    "    perf = predictor.evaluate(test_data)\n",
    "    random_results[model] = perf\n",
    "\n",
    "# Bayesian Optimization\n",
    "bayes_results = {}\n",
    "for model, params in param_grid.items():\n",
    "    predictor = TabularPredictor(label='target', path=f'models/{model}_bayes').fit(\n",
    "        train_data, hyperparameters={model: params},  # ✅ Corrected this line\n",
    "        hyperparameter_tune_kwargs={'searcher': 'bayesopt'}\n",
    "    )\n",
    "    perf = predictor.evaluate(test_data)\n",
    "    bayes_results[model] = perf\n",
    "\n",
    "# Create results table\n",
    "def format_results(results):\n",
    "    return pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "grid_df = format_results(grid_results)\n",
    "random_df = format_results(random_results)\n",
    "bayes_df = format_results(bayes_results)\n",
    "\n",
    "# Display comparison\n",
    "display(grid_df, random_df, bayes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       7.40 GB / 31.65 GB (23.4%)\n",
      "Disk Space Avail:   50.03 GB / 430.79 GB (11.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\GBM_grid\"\n",
      "Train Data Rows:    800\n",
      "Train Data Columns: 10\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7583.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 640, Val Rows: 160\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': [{'num_boost_round': 100, 'learning_rate': 0.1}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9125\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t0.9125\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.62s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 19501.6 rows/s (160 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (160 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\GBM_grid\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       7.40 GB / 31.65 GB (23.4%)\n",
      "Disk Space Avail:   50.03 GB / 430.79 GB (11.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\RF_grid\"\n",
      "Train Data Rows:    800\n",
      "Train Data Columns: 10\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7580.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 640, Val Rows: 160\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'RF': [{'n_estimators': 100, 'max_depth': 10}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: RandomForest ...\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForest': 1.0}\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.51s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4978.6 rows/s (160 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (160 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\RF_grid\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       7.75 GB / 31.65 GB (24.5%)\n",
      "Disk Space Avail:   50.03 GB / 430.79 GB (11.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\XT_grid\"\n",
      "Train Data Rows:    800\n",
      "Train Data Columns: 10\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7937.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 640, Val Rows: 160\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'XT': [{'n_estimators': 100, 'max_depth': 10}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: ExtraTrees ...\n",
      "\t0.8938\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTrees': 1.0}\n",
      "\t0.8938\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 0.48s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5072.0 rows/s (160 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (160 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\XT_grid\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.898674</td>\n",
       "      <td>0.794458</td>\n",
       "      <td>0.944681</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.978495</td>\n",
       "      <td>0.819820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.877366</td>\n",
       "      <td>0.750753</td>\n",
       "      <td>0.948983</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.913462</td>\n",
       "      <td>0.855856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XT</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.858235</td>\n",
       "      <td>0.712264</td>\n",
       "      <td>0.937443</td>\n",
       "      <td>0.863850</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.828829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  balanced_accuracy       mcc  ...        f1  precision    recall\n",
       "GBM     0.890           0.898674  0.794458  ...  0.892157   0.978495  0.819820\n",
       "RF      0.875           0.877366  0.750753  ...  0.883721   0.913462  0.855856\n",
       "XT      0.855           0.858235  0.712264  ...  0.863850   0.901961  0.828829\n",
       "\n",
       "[3 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\n",
    "df['target'] = y\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define AutoGluon-supported models & hyperparameter grids\n",
    "param_grid = {\n",
    "    'GBM': {'num_boost_round': 100, 'learning_rate': 0.1},  # Gradient Boosting Machine (LightGBM)\n",
    "    'RF': {'n_estimators': 100, 'max_depth': 10},           # Random Forest\n",
    "    'XT': {'n_estimators': 100, 'max_depth': 10}            # Extra Trees\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_results = {}\n",
    "for model, params in param_grid.items():\n",
    "    predictor = TabularPredictor(label='target', path=f'models/{model}_grid').fit(\n",
    "        train_data, hyperparameters={model: params}  # ✅ Corrected Model Names\n",
    "    )\n",
    "    perf = predictor.evaluate(test_data)\n",
    "    grid_results[model] = perf\n",
    "\n",
    "# Display results\n",
    "grid_df = pd.DataFrame.from_dict(grid_results, orient='index')\n",
    "display(grid_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)  # Reshape for one-hot encoding\n",
    "\n",
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = ohe.fit_transform(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"models/grid\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       7.03 GB / 31.65 GB (22.2%)\n",
      "Disk Space Avail:   49.54 GB / 430.79 GB (11.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"c:\\Users\\Parth\\OneDrive - iitgn.ac.in\\CS203_Lab_01-main\\New folder\\-CS-203-MLP-Model-Implementation-Experiment-Tracking-Hyperparameters\\models\\grid\"\n",
      "Train Data Rows:    120\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [0, 1, 2]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7196.20 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['feature_0', 'feature_1', 'feature_2', 'feature_3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['feature_0', 'feature_1', 'feature_2', 'feature_3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 96, Val Rows: 24\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'num_epochs': 5, 'learning_rate': 0.001, 'batch_size': 4, 'activation': 'relu', 'hidden_size': 16}],\n",
      "}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Hyperparameter tuning model: NeuralNetTorch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 02:56:15,069\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "Warning: Exception caused NeuralNetTorch to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2497, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 1744, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\hpo\\executors.py\", line 349, in initialize\n",
      "    hyperparameter_tune_kwargs[\"scheduler\"], hyperparameter_tune_kwargs[\"scheduler\"]\n",
      "KeyError: 'scheduler'\n",
      "'scheduler'\n",
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "Warning: AutoGluon did not successfully train any models\n",
      "AutoGluon training complete, total runtime = 1.21s ... Best model: None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, tuning_kwargs \u001b[38;5;129;01min\u001b[39;00m search_methods\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔍 Running \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m search...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmethod\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# AutoGluon tuning parameter\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     perf \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mevaluate(df_test)\n\u001b[0;32m     39\u001b[0m     results[method] \u001b[38;5;241m=\u001b[39m perf\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39mgargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1299\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_strategy \u001b[38;5;241m=\u001b[39m fit_strategy\n\u001b[1;32m-> 1299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1307\u001b[0m, in \u001b[0;36mTabularPredictor._fit\u001b[1;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_fit_kwargs)\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_post_fit_vars()\n\u001b[1;32m-> 1307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_post_fit_kwargs)\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1630\u001b[0m, in \u001b[0;36mTabularPredictor._post_fit\u001b[1;34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit, num_cpus, num_gpus, refit_full_kwargs, fit_strategy, raise_on_no_models_fitted)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_names():\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_no_models_fitted:\n\u001b[1;32m-> 1630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo models were trained successfully during fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1632\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Inspect the log output or increase verbosity to determine why no models were fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1633\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1634\u001b[0m         )\n\u001b[0;32m   1636\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: No models found, skipping post_fit logic...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call."
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame for AutoGluon\n",
    "df_train = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(4)])\n",
    "df_train['target'] = np.argmax(y_train, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "df_test = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(4)])\n",
    "df_test['target'] = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Define hyperparameter search space\n",
    "hyperparameters = {\n",
    "    'NN_TORCH': {  # Neural Network with PyTorch\n",
    "        'num_epochs': 5,\n",
    "        'learning_rate': 1e-3,\n",
    "        'batch_size': 4,\n",
    "        'activation': 'relu',\n",
    "        'hidden_size': 16,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define search methods\n",
    "search_methods = {\n",
    "    \"grid\": {\"searcher\": \"grid\"},\n",
    "    \"random\": {\"searcher\": \"random\"},\n",
    "    \"hyperband\": {\"searcher\": \"bayesopt\", \"scheduler\": \"hyperband\"},\n",
    "    \"bayesopt\": {\"searcher\": \"bayesopt\"},\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "# Perform Hyperparameter Tuning using Grid Search, Random Search, Hyperband, and Bayesian Optimization\n",
    "for method, tuning_kwargs in search_methods.items():\n",
    "    print(f\"\\n🔍 Running {method} search...\")\n",
    "    predictor = TabularPredictor(label=\"target\", path=f\"models/{method}\").fit(\n",
    "        df_train,\n",
    "        hyperparameters=hyperparameters,\n",
    "        hyperparameter_tune_kwargs=tuning_kwargs,  # AutoGluon tuning parameter\n",
    "    )\n",
    "    perf = predictor.evaluate(df_test)\n",
    "    results[method] = perf\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "print(\"\\n Hyperparameter Tuning Results:\\n\", results_df)\n",
    "\n",
    "# Get predictions from the best model (e.g., Grid Search)\n",
    "best_model = \"grid\"  # Change this to the best-performing method\n",
    "predictor_best = TabularPredictor.load(f\"models/{best_model}\")\n",
    "y_pred = predictor_best.predict(df_test.drop(columns=[\"target\"]))\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(df_test[\"target\"], y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Show 5 sample predictions\n",
    "df_test_sample = df_test.iloc[:5].copy()\n",
    "df_test_sample[\"Predicted\"] = predictor_best.predict(df_test_sample.drop(columns=[\"target\"]))\n",
    "\n",
    "print(\"\\n Sample Predictions:\\n\", df_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian search failed. Error: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\n",
      "\n",
      "Comparison Table:\n",
      "   Search Method                Configuration  Accuracy  F1 Score\n",
      "0           Grid  Epochs: 1, LR: 0.001, BS: 2  0.866667  0.857875\n",
      "1           Grid  Epochs: 1, LR: 0.001, BS: 4  0.800000  0.771429\n",
      "2           Grid  Epochs: 1, LR: 1e-05, BS: 2  0.533333  0.421333\n",
      "3           Grid  Epochs: 1, LR: 1e-05, BS: 4  0.500000  0.392000\n",
      "4           Grid  Epochs: 3, LR: 0.001, BS: 2  1.000000  1.000000\n",
      "5           Grid  Epochs: 3, LR: 0.001, BS: 4  1.000000  1.000000\n",
      "6           Grid  Epochs: 3, LR: 1e-05, BS: 2  0.633333  0.507359\n",
      "7           Grid  Epochs: 3, LR: 1e-05, BS: 4  0.633333  0.507359\n",
      "8         Random  Epochs: 3, LR: 0.001, BS: 4  1.000000  1.000000\n",
      "9         Random  Epochs: 3, LR: 0.001, BS: 4  1.000000  1.000000\n",
      "10        Random  Epochs: 3, LR: 0.001, BS: 4  1.000000  1.000000\n",
      "11        Random  Epochs: 3, LR: 0.001, BS: 4  1.000000  1.000000\n",
      "12        Random  Epochs: 3, LR: 0.001, BS: 4  1.000000  1.000000\n",
      "13     Hyperband                       Failed       NaN       NaN\n",
      "14         Bayes                       Failed       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "# 1. Data Preparation\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)  # Reshape for one-hot encoding\n",
    "\n",
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = ohe.fit_transform(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrames for AutoGluon\n",
    "X_train = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "X_test = pd.DataFrame(X_test, columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
    "y_train = pd.DataFrame(y_train, columns=[f\"target_{i}\" for i in range(y_train.shape[1])])\n",
    "y_test = pd.DataFrame(y_test, columns=[f\"target_{i}\" for i in range(y_test.shape[1])])\n",
    "\n",
    "# Concatenate features and target for AutoGluon\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# AutoGluon expects a single target column for classification\n",
    "# We need to determine the predicted class from the one-hot encoded targets\n",
    "\n",
    "def convert_onehot_to_class(df, target_columns):\n",
    "    \"\"\"Converts one-hot encoded target columns to a single class label.\"\"\"\n",
    "    class_labels = df[target_columns].idxmax(axis=1).str.replace('target_', '').astype(int)\n",
    "    return class_labels\n",
    "\n",
    "target_columns = [col for col in train_data.columns if col.startswith('target_')]\n",
    "train_data['target'] = convert_onehot_to_class(train_data, target_columns)\n",
    "test_data['target'] = convert_onehot_to_class(test_data, target_columns)\n",
    "\n",
    "# Drop the one-hot encoded target columns\n",
    "train_data = train_data.drop(columns=target_columns)\n",
    "test_data = test_data.drop(columns=target_columns)\n",
    "\n",
    "train_data = TabularDataset(train_data)\n",
    "test_data = TabularDataset(test_data)\n",
    "\n",
    "# 2. Define the search space (Simplified initially)\n",
    "search_space = {\n",
    "    \"NN_TORCH\": {\n",
    "        \"num_epochs\": [1, 3],\n",
    "        \"learning_rate\": [1e-3, 1e-5],\n",
    "        \"batch_size\": [2, 4],\n",
    "    }\n",
    "}\n",
    "\n",
    "def evaluate_model(predictor, test_data):\n",
    "    \"\"\"Evaluates the trained model and returns accuracy and F1 score.\"\"\"\n",
    "    try:\n",
    "        y_true = test_data[\"target\"].to_numpy()\n",
    "        X_test = test_data.drop(columns=[\"target\"])\n",
    "        y_pred = predictor.predict(X_test).to_numpy()\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "        return accuracy, f1\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        return np.nan, np.nan  # Return NaN values if evaluation fails\n",
    "\n",
    "\n",
    "# 3. Implement Grid Search\n",
    "def grid_search(train_data, test_data, search_space):\n",
    "    \"\"\"Performs grid search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for num_epochs in search_space[\"NN_TORCH\"][\"num_epochs\"]:\n",
    "        for learning_rate in search_space[\"NN_TORCH\"][\"learning_rate\"]:\n",
    "            for batch_size in search_space[\"NN_TORCH\"][\"batch_size\"]:\n",
    "                hyperparameters = {\n",
    "                    \"NN_TORCH\": {\n",
    "                        \"num_epochs\": num_epochs,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"batch_size\": batch_size,\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                try:\n",
    "                    predictor = TabularPredictor(\n",
    "                        label=\"target\", eval_metric=\"accuracy\"\n",
    "                    )\n",
    "                    predictor.fit(\n",
    "                        train_data,\n",
    "                        hyperparameters=hyperparameters,\n",
    "                        time_limit=60,\n",
    "                        verbosity=0,\n",
    "                    )\n",
    "\n",
    "                    accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "                    config = f\"Epochs: {num_epochs}, LR: {learning_rate}, BS: {batch_size}\"\n",
    "                    results.append([\"Grid\", config, accuracy, f1])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Grid search failed for config: {config}. Error: {e}\")\n",
    "                    results.append([\"Grid\", config, np.nan, np.nan])  # Append NaN values\n",
    "\n",
    "    return results\n",
    "\n",
    "# 4. Implement Random Search\n",
    "def random_search(train_data, test_data, search_space, num_trials=5):\n",
    "    \"\"\"Performs random search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    for i in range(num_trials):\n",
    "        # Randomly sample hyperparameters\n",
    "        num_epochs = np.random.choice(search_space[\"NN_TORCH\"][\"num_epochs\"])\n",
    "        learning_rate = np.random.choice(search_space[\"NN_TORCH\"][\"learning_rate\"])\n",
    "        batch_size = np.random.choice(search_space[\"NN_TORCH\"][\"batch_size\"])\n",
    "\n",
    "        hyperparameters = {\n",
    "            \"NN_TORCH\": {\n",
    "                \"num_epochs\": num_epochs,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"batch_size\": batch_size,\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            predictor = TabularPredictor(label=\"target\", eval_metric=\"accuracy\")\n",
    "            predictor.fit(\n",
    "                train_data,\n",
    "                hyperparameters=hyperparameters,\n",
    "                time_limit=60,\n",
    "                verbosity=0,\n",
    "            )\n",
    "            accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "            config = f\"Epochs: {num_epochs}, LR: {learning_rate}, BS: {batch_size}\"\n",
    "            results.append([\"Random\", config, accuracy, f1])\n",
    "        except Exception as e:\n",
    "            print(f\"Random search failed for config: {config}. Error: {e}\")\n",
    "            results.append([\"Random\", config, np.nan, np.nan])\n",
    "\n",
    "    return results\n",
    "\n",
    "# 5. Implement Hyperband Search\n",
    "def hyperband_search(train_data, test_data, search_space, num_trials=5):\n",
    "    \"\"\"Performs hyperband search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    hyperparameter_tune_kwargs = {\n",
    "        \"scheduler\": \"hyperband\",\n",
    "        \"searcher\": \"random\",  # You can also use \"bayes\"\n",
    "        \"num_trials\": num_trials,\n",
    "    }\n",
    "    try:\n",
    "        predictor = TabularPredictor(label=\"target\", eval_metric=\"accuracy\")\n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            hyperparameters=search_space,\n",
    "            time_limit=60,\n",
    "            verbosity=0,\n",
    "            hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "        )\n",
    "\n",
    "        # Extract best config from leaderboard\n",
    "        leaderboard = predictor.leaderboard(silent=True)\n",
    "        best_config = leaderboard.iloc[0]\n",
    "        accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "        results.append(\n",
    "            [\n",
    "                \"Hyperband\",\n",
    "                str(best_config[\"model\"]),\n",
    "                accuracy,\n",
    "                f1,\n",
    "            ]\n",
    "        )  # Use the best model for evaluation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Hyperband search failed. Error: {e}\")\n",
    "        results.append([\"Hyperband\", \"Failed\", np.nan, np.nan])\n",
    "    return results\n",
    "\n",
    "# 6. Implement Bayesian Optimization Search\n",
    "def bayesian_optimization_search(train_data, test_data, search_space, num_trials=5):\n",
    "    \"\"\"Performs Bayesian optimization search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    hyperparameter_tune_kwargs = {\n",
    "        \"scheduler\": \"local\",  # Use local scheduler for Bayesian optimization\n",
    "        \"searcher\": \"bayes\",\n",
    "        \"num_trials\": num_trials,\n",
    "    }\n",
    "    try:\n",
    "        predictor = TabularPredictor(label=\"target\", eval_metric=\"accuracy\")\n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            hyperparameters=search_space,\n",
    "            time_limit=60,\n",
    "            verbosity=0,\n",
    "            hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "        )\n",
    "        # Extract best config from leaderboard\n",
    "        leaderboard = predictor.leaderboard(silent=True)\n",
    "        best_config = leaderboard.iloc[0]\n",
    "        accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "        results.append(\n",
    "            [\n",
    "                \"Bayes\",\n",
    "                str(best_config[\"model\"]),\n",
    "                accuracy,\n",
    "                f1,\n",
    "            ]\n",
    "        )  # Use the best model for evaluation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Bayesian search failed. Error: {e}\")\n",
    "        results.append([\"Bayes\", \"Failed\", np.nan, np.nan])\n",
    "    return results\n",
    "\n",
    "# Run the searches\n",
    "grid_results = grid_search(train_data, test_data, search_space)\n",
    "random_results = random_search(train_data, test_data, search_space)\n",
    "hyperband_results = hyperband_search(train_data, test_data, search_space, num_trials=5)\n",
    "bayes_results = bayesian_optimization_search(\n",
    "    train_data, test_data, search_space, num_trials=5\n",
    ")\n",
    "\n",
    "# Combine all results\n",
    "all_results = grid_results + random_results + hyperband_results + bayes_results\n",
    "\n",
    "# 7. Create the comparison table\n",
    "results_df = pd.DataFrame(\n",
    "    all_results, columns=[\"Search Method\", \"Configuration\", \"Accuracy\", \"F1 Score\"]\n",
    ")\n",
    "print(\"\\nComparison Table:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'space' from 'autogluon.core' (C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogluon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m space  \u001b[38;5;66;03m# Corrected import statement\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 1. Data Preparation\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m iris \u001b[38;5;241m=\u001b[39m load_iris()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'space' from 'autogluon.core' (C:\\Users\\Parth\\AppData\\Roaming\\Python\\Python310\\site-packages\\autogluon\\core\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "from autogluon.core import space  # Corrected import statement\n",
    "\n",
    "# 1. Data Preparation\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)  # Reshape for one-hot encoding\n",
    "\n",
    "# One-hot encoding\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = ohe.fit_transform(y)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrames for AutoGluon\n",
    "X_train = pd.DataFrame(X_train, columns=[f\"feature_{i}\" for i in range(X_train.shape[1])])\n",
    "X_test = pd.DataFrame(X_test, columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
    "y_train = pd.DataFrame(y_train, columns=[f\"target_{i}\" for i in range(y_train.shape[1])])\n",
    "y_test = pd.DataFrame(y_test, columns=[f\"target_{i}\" for i in range(y_test.shape[1])])\n",
    "\n",
    "# Concatenate features and target for AutoGluon\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# AutoGluon expects a single target column for classification\n",
    "# We need to determine the predicted class from the one-hot encoded targets\n",
    "\n",
    "def convert_onehot_to_class(df, target_columns):\n",
    "    \"\"\"Converts one-hot encoded target columns to a single class label.\"\"\"\n",
    "    class_labels = df[target_columns].idxmax(axis=1).str.replace('target_', '').astype(int)\n",
    "    return class_labels\n",
    "\n",
    "target_columns = [col for col in train_data.columns if col.startswith('target_')]\n",
    "train_data['target'] = convert_onehot_to_class(train_data, target_columns)\n",
    "test_data['target'] = convert_onehot_to_class(test_data, target_columns)\n",
    "\n",
    "# Drop the one-hot encoded target columns\n",
    "train_data = train_data.drop(columns=target_columns)\n",
    "test_data = test_data.drop(columns=target_columns)\n",
    "\n",
    "train_data = TabularDataset(train_data)\n",
    "test_data = TabularDataset(test_data)\n",
    "\n",
    "# 2. Define the search space (using autogluon.space for ranges)\n",
    "search_space = {\n",
    "    \"NN_TORCH\": {\n",
    "        \"num_epochs\": space.Int(lower=1, upper=5, default=3),  # Integer range for epochs\n",
    "        \"learning_rate\": space.Categorical(1e-3, 1e-5),  # Categorical for learning rate\n",
    "        \"batch_size\": space.Categorical(2, 4),  # Categorical for batch size\n",
    "    }\n",
    "}\n",
    "\n",
    "def evaluate_model(predictor, test_data):\n",
    "    \"\"\"Evaluates the trained model and returns accuracy and F1 score.\"\"\"\n",
    "    try:\n",
    "        y_true = test_data[\"target\"].to_numpy()\n",
    "        X_test = test_data.drop(columns=[\"target\"])\n",
    "        y_pred = predictor.predict(X_test).to_numpy()\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "        return accuracy, f1\n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        return np.nan, np.nan  # Return NaN values if evaluation fails\n",
    "\n",
    "\n",
    "# 3. Implement Grid Search\n",
    "def grid_search(train_data, test_data, search_space):\n",
    "    \"\"\"Performs grid search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    # Iterate over all combinations of hyperparameters\n",
    "    for num_epochs in [1, 3, 5]:\n",
    "        for learning_rate in [1e-3, 1e-5]:\n",
    "            for batch_size in [2, 4]:\n",
    "                hyperparameters = {\n",
    "                    \"NN_TORCH\": {\n",
    "                        \"num_epochs\": num_epochs,\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"batch_size\": batch_size,\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                try:\n",
    "                    predictor = TabularPredictor(\n",
    "                        label=\"target\", eval_metric=\"accuracy\", problem_type=\"multiclass\"\n",
    "                    )\n",
    "                    predictor.fit(\n",
    "                        train_data,\n",
    "                        hyperparameters=hyperparameters,\n",
    "                        time_limit=60,\n",
    "                        verbosity=0,\n",
    "                    )\n",
    "\n",
    "                    accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "                    config = f\"Epochs: {num_epochs}, LR: {learning_rate}, BS: {batch_size}\"\n",
    "                    results.append([\"Grid\", config, accuracy, f1])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Grid search failed for config: {config}. Error: {e}\")\n",
    "                    results.append([\"Grid\", config, np.nan, np.nan])  # Append NaN values\n",
    "\n",
    "    return results\n",
    "\n",
    "# 4. Implement Random Search\n",
    "def random_search(train_data, test_data, search_space, num_trials=5):\n",
    "    \"\"\"Performs random search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    for i in range(num_trials):\n",
    "        # Randomly sample hyperparameters\n",
    "        num_epochs = np.random.choice([1, 3, 5])\n",
    "        learning_rate = np.random.choice([1e-3, 1e-5])\n",
    "        batch_size = np.random.choice([2, 4])\n",
    "\n",
    "        hyperparameters = {\n",
    "            \"NN_TORCH\": {\n",
    "                \"num_epochs\": num_epochs,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"batch_size\": batch_size,\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            predictor = TabularPredictor(label=\"target\", eval_metric=\"accuracy\", problem_type=\"multiclass\")\n",
    "            predictor.fit(\n",
    "                train_data,\n",
    "                hyperparameters=hyperparameters,\n",
    "                time_limit=60,\n",
    "                verbosity=0,\n",
    "            )\n",
    "            accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "            config = f\"Epochs: {num_epochs}, LR: {learning_rate}, BS: {batch_size}\"\n",
    "            results.append([\"Random\", config, accuracy, f1])\n",
    "        except Exception as e:\n",
    "            print(f\"Random search failed for config: {config}. Error: {e}\")\n",
    "            results.append([\"Random\", config, np.nan, np.nan])\n",
    "\n",
    "    return results\n",
    "\n",
    "# 5. Implement Hyperband Search\n",
    "def hyperband_search(train_data, test_data, search_space, num_trials=5):\n",
    "    \"\"\"Performs hyperband search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    hyperparameter_tune_kwargs = {\n",
    "        \"scheduler\": \"hyperband\",\n",
    "        \"searcher\": \"random\",  # Explicitly set searcher to \"random\"\n",
    "        \"num_trials\": num_trials,\n",
    "    }\n",
    "    try:\n",
    "        predictor = TabularPredictor(label=\"target\", eval_metric=\"accuracy\", problem_type=\"multiclass\")\n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            hyperparameters=search_space,\n",
    "            time_limit=60,\n",
    "            verbosity=0, # Try increasing verbosity for debugging\n",
    "            hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "        )\n",
    "\n",
    "        # Extract best config from leaderboard\n",
    "        leaderboard = predictor.leaderboard(silent=True)\n",
    "        best_config = leaderboard.iloc[0]\n",
    "        accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "        results.append(\n",
    "            [\n",
    "                \"Hyperband\",\n",
    "                str(best_config[\"model\"]),\n",
    "                accuracy,\n",
    "                f1,\n",
    "            ]\n",
    "        )  # Use the best model for evaluation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Hyperband search failed. Error: {e}\")\n",
    "        results.append([\"Hyperband\", \"Failed\", np.nan, np.nan])\n",
    "    return results\n",
    "\n",
    "# 6. Implement Bayesian Optimization Search\n",
    "def bayesian_optimization_search(train_data, test_data, search_space, num_trials=5):\n",
    "    \"\"\"Performs Bayesian optimization search using AutoGluon.\"\"\"\n",
    "    results = []\n",
    "    hyperparameter_tune_kwargs = {\n",
    "        \"scheduler\": \"local\",  # Use local scheduler for Bayesian optimization\n",
    "        \"searcher\": \"bayes\",  # Explicitly set searcher to \"bayes\"\n",
    "        \"num_trials\": num_trials,\n",
    "    }\n",
    "    try:\n",
    "        predictor = TabularPredictor(label=\"target\", eval_metric=\"accuracy\", problem_type=\"multiclass\")\n",
    "        predictor.fit(\n",
    "            train_data,\n",
    "            hyperparameters=search_space,\n",
    "            time_limit=60,\n",
    "            verbosity=0, # Try increasing verbosity for debugging\n",
    "            hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "        )\n",
    "        # Extract best config from leaderboard\n",
    "        leaderboard = predictor.leaderboard(silent=True)\n",
    "        best_config = leaderboard.iloc[0]\n",
    "        accuracy, f1 = evaluate_model(predictor, test_data)\n",
    "        results.append(\n",
    "            [\n",
    "                \"Bayes\",\n",
    "                str(best_config[\"model\"]),\n",
    "                accuracy,\n",
    "                f1,\n",
    "            ]\n",
    "        )  # Use the best model for evaluation\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Bayesian search failed. Error: {e}\")\n",
    "        results.append([\"Bayes\", \"Failed\", np.nan, np.nan])\n",
    "    return results\n",
    "\n",
    "# Run the searches\n",
    "grid_results = grid_search(train_data, test_data, search_space)\n",
    "random_results = random_search(train_data, test_data, search_space)\n",
    "hyperband_results = hyperband_search(train_data, test_data, search_space, num_trials=5)\n",
    "bayes_results = bayesian_optimization_search(\n",
    "    train_data, test_data, search_space, num_trials=5\n",
    ")\n",
    "\n",
    "# Combine all results\n",
    "all_results = grid_results + random_results + hyperband_results + bayes_results\n",
    "\n",
    "# 7. Create the comparison table\n",
    "results_df = pd.DataFrame(\n",
    "    all_results, columns=[\"Search Method\", \"Configuration\", \"Accuracy\", \"F1 Score\"]\n",
    ")\n",
    "print(\"\\nComparison Table:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
